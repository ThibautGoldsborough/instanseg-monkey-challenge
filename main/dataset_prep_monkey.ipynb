{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instanseg.utils.data_download import create_raw_datasets_dir, create_processed_datasets_dir, download_and_extract\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import fastremap\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from instanseg.utils.utils import show_images, _move_channel_axis\n",
    "#aws s3 cp --no-sign-request s3://monkey-training/ ./ --recursive\n",
    "monkey_dir = Path(\"../Raw_Datasets/Monkey\")\n",
    "\n",
    "files = sorted(os.listdir(os.path.join(monkey_dir ,\"annotations\",\"xml\")))\n",
    "\n",
    "label_ids = []\n",
    "means_list = []\n",
    "annotations_dict = {}\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "for file in tqdm(files):\n",
    "\n",
    "    split = np.random.choice([\"train\", \"val\"], p=[0.8, 0.2])\n",
    " \n",
    "    img_pascpg_path = Path(monkey_dir) / (\"images/pas-cpg/\" + file.split(\".\")[0] + \"_PAS_CPG.tif\")\n",
    "    img_pasdiagnostic_path = Path(monkey_dir) / (\"images/pas-diagnostic/\" + file.split(\".\")[0] + \"_PAS_Diagnostic.tif\")\n",
    "   # img_pasoriginal_path = Path(monkey_dir) / (\"images/pas-original/\" + file.split(\".\")[0] + \"_PAS_Original.tif\")\n",
    "    ihc_path = Path(monkey_dir) / (\"images/ihc/\" + file.split(\".\")[0] + \"_IHC_CPG.tif\")\n",
    "    \n",
    "    from tiffslide import TiffSlide\n",
    "    slidepascpg = TiffSlide(img_pascpg_path)\n",
    "    slideihc = TiffSlide(ihc_path)\n",
    "\n",
    "\n",
    "    tree = ET.parse(monkey_dir/(\"annotations/xml/\"+file))\n",
    "    root = tree.getroot()  # Get the root of the XML\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if split == \"val\":\n",
    "        destination_img = \"/home/cdt/Documents/Projects/monkey-challenge-instanseg/evaluation/validation_set/images/kidney-transplant-biopsy-wsi-pas/\"\n",
    "        destination_mask = \"/home/cdt/Documents/Projects/monkey-challenge-instanseg/evaluation/validation_set/images/tissue-mask/\"\n",
    "        \n",
    "        #move images to inference folder\n",
    "        import shutil\n",
    "        shutil.copy(monkey_dir / (\"images/pas-cpg/\" + file.split(\".\")[0] + \"_PAS_CPG.tif\"), destination_img)\n",
    "        shutil.copy(monkey_dir / (\"images/tissue-masks/\" + file.split(\".\")[0] + \"_mask.tif\"), destination_mask)\n",
    "        \n",
    "        shutil.copy(monkey_dir / (\"annotations/json/\" + file.split(\".\")[0] + \"_inflammatory-cells.json\"), \n",
    "        '/home/cdt/Documents/Projects/monkey-challenge-instanseg/evaluation/ground_truth')\n",
    "\n",
    "        shutil.copy(monkey_dir / (\"annotations/json/\" + file.split(\".\")[0] + \"_lymphocytes.json\"), \n",
    "        '/home/cdt/Documents/Projects/monkey-challenge-instanseg/evaluation/ground_truth')\n",
    "\n",
    "        shutil.copy(monkey_dir / (\"annotations/json/\" + file.split(\".\")[0] + \"_monocytes.json\"), \n",
    "        '/home/cdt/Documents/Projects/monkey-challenge-instanseg/evaluation/ground_truth')\n",
    "\n",
    "    coords = []\n",
    "\n",
    "    annotations_dict[file] = []\n",
    "\n",
    "    # Iterate over each annotation and extract relevant information\n",
    "    for annotation in root.findall('.//Annotation'):\n",
    "        name = annotation.get('Name')\n",
    "        part_of_group = annotation.get('PartOfGroup')\n",
    "        _type = annotation.get('Type')\n",
    "      \n",
    "        if _type == \"Polygon\":\n",
    "            coords_ROI = []\n",
    "            for coordinate in annotation.findall('.//Coordinate'):\n",
    "                x = float(coordinate.get('X'))\n",
    "                y = float(coordinate.get('Y'))\n",
    "                coords_ROI.append([x, y])\n",
    "\n",
    "            coords_ROI = np.array(coords_ROI)\n",
    "\n",
    "            x_min, y_min = coords_ROI.min(axis=0)\n",
    "            x_max, y_max = coords_ROI.max(axis=0)\n",
    "            bbox_width = int(x_max - x_min)\n",
    "            bbox_height = int(y_max - y_min)\n",
    "\n",
    "            # Read the bounding box from the slide\n",
    "            rgb_data = slidepascpg.read_region(\n",
    "                (int(x_min), int(y_min)),\n",
    "                0,\n",
    "                (bbox_width, bbox_height),\n",
    "                as_array=True,\n",
    "            )\n",
    "\n",
    "            ihc_data = slideihc.read_region(\n",
    "                (int(x_min), int(y_min)),\n",
    "                0,\n",
    "                (bbox_width, bbox_height),\n",
    "                as_array=True,\n",
    "            )\n",
    "\n",
    "\n",
    "            mask = Image.new(\"L\", (bbox_width, bbox_height), 0)\n",
    "            polygon = coords_ROI - [x_min, y_min]  # Translate polygon to local bbox coordinates\n",
    "            ImageDraw.Draw(mask).polygon(polygon.flatten().tolist(), outline=1, fill=1)\n",
    "            # Convert the mask to a NumPy array\n",
    "            binary_mask = np.array(mask)\n",
    "\n",
    "            annotations_dict[file].append({ \"split\": split,\n",
    "                                            \"pas-cpg\":rgb_data,\n",
    "                                            \"ihc\":ihc_data,\n",
    "                                            \"polygon\": coords_ROI, \n",
    "                                            \"mask\": binary_mask, \n",
    "                                            \"bbox\" : [x_min, y_min, x_max, y_max], \n",
    "                                            \"dots\" : []})\n",
    "\n",
    "            #show_images(rgb_data)\n",
    "\n",
    "    for annotation in root.findall('.//Annotation'):\n",
    "        name = annotation.get('Name')\n",
    "        part_of_group = annotation.get('PartOfGroup')\n",
    "        _type = annotation.get('Type')\n",
    "        \n",
    "        if _type == \"Dot\":\n",
    "            # Find the coordinates\n",
    "            coordinates = annotation.find('.//Coordinate')\n",
    "            x = int(float(coordinates.get('X')))\n",
    "            y = int(float(coordinates.get('Y')))\n",
    "            c = 0 if part_of_group == \"lymphocytes\" else 1\n",
    "\n",
    "            for i,annotation in enumerate(annotations_dict[file]):\n",
    "                if annotation[\"bbox\"][0] < x < annotation[\"bbox\"][2] and annotation[\"bbox\"][1] < y < annotation[\"bbox\"][3]:\n",
    "                    annotations_dict[file][i][\"dots\"].append([y - annotation[\"bbox\"][1] ,x - annotation[\"bbox\"][0],c])\n",
    "\n",
    "    \n",
    "                        \n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leukocytes_dots = 0\n",
    "detected_leukocytes = 0\n",
    "\n",
    "def normalise_HE(x):\n",
    "    import torch\n",
    "    import torchstain\n",
    "    from instanseg.utils.utils import _move_channel_axis\n",
    "\n",
    "    x = _to_tensor_float32(x)\n",
    "    device = x.device\n",
    "    normalizer = torchstain.normalizers.MacenkoNormalizer(backend='torch')\n",
    "    normalizer.maxCRef = normalizer.maxCRef.to(device)\n",
    "    normalizer.HERef = normalizer.HERef.to(device)\n",
    "    norm = normalizer.normalize(I=x, stains=False, Io = 240, beta = 0.01)\n",
    "    norm = torch.clamp(norm[0], 0, 255)\n",
    "    norm = _move_channel_axis(norm)\n",
    "    return norm\n",
    "\n",
    "import os\n",
    "from instanseg.utils.pytorch_utils import get_masked_patches\n",
    "from instanseg.instanseg import _to_tensor_float32, _rescale_to_pixel_size\n",
    "import torchstain\n",
    "from instanseg import InstanSeg\n",
    "\n",
    "os.environ[\"INSTANSEG_BIOIMAGEIO_PATH\"] = '/home/cdt/Documents/Projects/InstanSeg/instanseg_thibaut/instanseg/bioimageio_models/'\n",
    "os.environ['INSTANSEG_DATASET_PATH'] = \"../datasets/\"\n",
    "\n",
    "brightfield_nuclei = InstanSeg(\"brightfield_v2\", verbosity = 0)\n",
    "\n",
    "patch_size = 128\n",
    "destination_pixel_size = 0.5 # 2420\n",
    "rescale_output = False if destination_pixel_size == 0.5 else True\n",
    "\n",
    "image_types  = [\"cpg\"]#, \"ihc\"]\n",
    "\n",
    "for image_type in image_types:\n",
    "\n",
    "  if image_type == \"cpg\":\n",
    "    image_key  = \"pas-cpg\"\n",
    "  else:\n",
    "    image_key = \"ihc\"\n",
    "\n",
    "\n",
    "  device = \"cpu\"\n",
    "\n",
    "  np.random.seed(0)\n",
    "\n",
    "\n",
    "  import h5py\n",
    "  with h5py.File(Path(os.environ['INSTANSEG_DATASET_PATH']) / f\"monkey_{image_type}_gold_norm.h5\", \"w\") as f:\n",
    "\n",
    "      f.attrs['class_names'] = str({\"0\": \"lymphocytes\", \"1\": \"monocytes\", \"2\" : \"other\"})  # Convert to string since HDF5 attributes must be simple types\n",
    "      f.attrs['pixel_size'] = destination_pixel_size\n",
    "\n",
    "      for split in ['train', 'val']:\n",
    "          f.create_dataset(f\"{split}/data\", shape=(0, 4, patch_size, patch_size),\n",
    "          dtype=np.uint8, maxshape=(None, 4, patch_size, patch_size),\n",
    "          chunks=(1, 4, patch_size, patch_size),)\n",
    "          f.create_dataset(f\"{split}/labels\", shape=(0, 1), dtype=np.uint8, maxshape=(None, 1))\n",
    "\n",
    "\n",
    "      for file in tqdm(annotations_dict.keys()):\n",
    "          split = annotations_dict[file][0][\"split\"]\n",
    "\n",
    "          for annotation in annotations_dict[file]:\n",
    "\n",
    "              try:\n",
    "\n",
    "                array = normalise_HE(annotation[\"pas-cpg\"]).float()\n",
    "\n",
    "              except:\n",
    "                array = _to_tensor_float32(annotation[\"pas-cpg\"])\n",
    "\n",
    "              \n",
    "\n",
    "      \n",
    "              labels , input_tensor = brightfield_nuclei.eval_medium_image(array,\n",
    "              pixel_size = 0.2420, rescale_output = rescale_output, seed_threshold = 0.05, tile_size= 1024)\n",
    "\n",
    "              dots = torch.tensor(annotation[\"dots\"]).to(device)\n",
    "              dots[:,:2] = dots[:,:2] * 0.2420 / destination_pixel_size\n",
    "\n",
    "              mask = _rescale_to_pixel_size(_to_tensor_float32(annotation[\"mask\"]), 0.2420, destination_pixel_size).to(device)\n",
    "              \n",
    "              labels = labels.to(device) * torch.tensor(mask).bool()\n",
    "              canvas = torch.zeros_like(labels)\n",
    "              dots = torch.tensor(dots, dtype=torch.long)\n",
    "              canvas[:,:,dots[:,0],dots[:,1]] = dots[:,2].float() + 1\n",
    "              monocytes = labels * torch.isin(labels,labels * (canvas == 2).float()).float()\n",
    "              lymphocytes = labels * torch.isin(labels,labels * (canvas == 1).float()).float()\n",
    "              other_cells = (labels * ~torch.isin(labels,labels * (canvas > 0).float())).float()\n",
    "\n",
    "              img_tensor = _rescale_to_pixel_size(_to_tensor_float32(annotation[image_key]), 0.2420, destination_pixel_size).byte().to(device)\n",
    "\n",
    "              img_tensor = normalise_HE(img_tensor)\n",
    "\n",
    "\n",
    "              assert img_tensor.shape[-2:] == labels.shape[-2:]\n",
    "              detected_leukocytes += len(torch.unique(monocytes + lymphocytes)) - 1\n",
    "              leukocytes_dots += len(dots)\n",
    "\n",
    "\n",
    "              if len(torch.unique(monocytes)) > 1:\n",
    "                crops,masks = get_masked_patches(monocytes,img_tensor, patch_size=patch_size)\n",
    "                crops = (crops).to(torch.uint8)\n",
    "                masks = (masks).to(torch.uint8)\n",
    "                x_monocytes =(torch.cat((crops,masks),dim= 1))\n",
    "                y_monocytes = torch.zeros(len(x_monocytes),dtype = torch.long) + 1\n",
    "              else:\n",
    "                x_monocytes = torch.zeros(0,4,patch_size,patch_size).to(device)\n",
    "                y_monocytes = torch.zeros(0,dtype = torch.long) + 1\n",
    "\n",
    "\n",
    "              if len(torch.unique(lymphocytes)) > 1:\n",
    "                crops,masks = get_masked_patches(lymphocytes,img_tensor, patch_size=patch_size)\n",
    "                crops = (crops).to(torch.uint8)\n",
    "                masks = (masks).to(torch.uint8)\n",
    "                x_lymphocytes =(torch.cat((crops,masks),dim= 1))\n",
    "                y_lymphocytes = torch.zeros(len(x_lymphocytes),dtype = torch.long) + 0\n",
    "              else:\n",
    "                x_lymphocytes = torch.zeros(0,4,patch_size,patch_size).to(device)\n",
    "                y_lymphocytes = torch.zeros(0,dtype = torch.long) + 0\n",
    "\n",
    "              if len(torch.unique(other_cells)) > 1:\n",
    "                crops,masks = get_masked_patches(other_cells,img_tensor, patch_size=patch_size)\n",
    "                crops = (crops).to(torch.uint8)\n",
    "                masks = (masks).to(torch.uint8)\n",
    "                x_other =(torch.cat((crops,masks),dim= 1))\n",
    "                y_other = torch.zeros(len(x_other),dtype = torch.long) + 2\n",
    "              else:\n",
    "                x_other = torch.zeros(0,4,patch_size,patch_size).to(device)\n",
    "                y_other = torch.zeros(0,dtype = torch.long) + 2\n",
    "\n",
    "              x = torch.cat((x_monocytes,x_lymphocytes,x_other),dim = 0)\n",
    "              y = torch.cat((y_monocytes,y_lymphocytes,y_other),dim = 0).numpy()[:,None]\n",
    "\n",
    "              if len(x) != len(y):\n",
    "                    pdb.set_trace()\n",
    "\n",
    "              data_ds = f[f\"{split}/data\"]\n",
    "              labels_ds = f[f\"{split}/labels\"]\n",
    "\n",
    "              data_ds.resize((data_ds.shape[0] + x.shape[0],) + x.shape[1:])\n",
    "              data_ds[-x.shape[0]:, ...] = (x).cpu().numpy().astype(np.uint8)\n",
    "              labels_ds.resize((labels_ds.shape[0] + y.shape[0],) + y.shape[1:])\n",
    "              labels_ds[-y.shape[0]:, ...] = y.astype(np.uint8)\n",
    "\n",
    "          \n",
    "\n",
    "  undetected_percent = ( leukocytes_dots - detected_leukocytes) / leukocytes_dots\n",
    "  print(f\"Detected {detected_leukocytes} out of {leukocytes_dots} dots. { 100 - undetected_percent * 100:.2f}% detected\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = _to_tensor_float32(array).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import fastremap\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from instanseg.utils.utils import show_images, _move_channel_axis\n",
    "from tiling import get_random_non_empty_tiles\n",
    "from tiffslide import TiffSlide\n",
    "\n",
    "os.environ[\"INSTANSEG_BIOIMAGEIO_PATH\"] = '/home/cdt/Documents/Projects/InstanSeg/instanseg_thibaut/instanseg/bioimageio_models/'\n",
    "os.environ['INSTANSEG_DATASET_PATH'] = \"../datasets/\"\n",
    "\n",
    "\n",
    "#os.environ['INSTANSEG_DATASET_PATH'] = \"/run/user/1000/gvfs/smb-share:server=cmvm.datastore.ed.ac.uk,share=igmm/bankhead-lab/thibaut_goldsborough/processed_datasets/\"\n",
    "\n",
    "\n",
    "from instanseg.instanseg import InstanSeg, _rescale_to_pixel_size, _to_tensor_float32, to_ndim\n",
    "from instanseg.utils.pytorch_utils import get_masked_patches\n",
    "brightfield_nuclei = InstanSeg(\"brightfield_v2\", verbosity = 0)\n",
    "\n",
    "import os\n",
    "os.environ[\"INSTANSEG_OUTPUT_PATH\"] = \"../outputs/\"\n",
    "from utils import get_classifier\n",
    "classifier = get_classifier(\"1922985\").to(\"cuda\").eval()\n",
    "\n",
    "classifier_he = get_classifier(\"test_0\").to(\"cuda\").eval()\n",
    "\n",
    "import ttach as tta\n",
    "transforms = tta.Compose(\n",
    "    [\n",
    "        tta.HorizontalFlip(),\n",
    "        tta.Rotate90(angles=[0, 180]),  \n",
    "    ]\n",
    ")\n",
    "tta_classifier = tta.ClassificationTTAWrapper(classifier, transforms, merge_mode='mean').eval()\n",
    "\n",
    "\n",
    "patch_size = 128\n",
    "destination_pixel_size = 0.5\n",
    "normalise = True\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "monkey_dir = Path(\"../Raw_Datasets/Monkey\")\n",
    "files = os.listdir(os.path.join(monkey_dir ,\"annotations\",\"xml\"))\n",
    "\n",
    "\n",
    "def normalise_HE(x):\n",
    "    import torch\n",
    "    import torchstain\n",
    "    from instanseg.utils.utils import _move_channel_axis\n",
    "    device = x.device\n",
    "    normalizer = torchstain.normalizers.MacenkoNormalizer(backend='torch')\n",
    "    normalizer.maxCRef = normalizer.maxCRef.to(device)\n",
    "    normalizer.HERef = normalizer.HERef.to(device)\n",
    "    norm = normalizer.normalize(I=x, stains=False, Io = 240, beta = 0.01)\n",
    "    norm = torch.clamp(norm[0], 0, 255)\n",
    "    norm = _move_channel_axis(norm)\n",
    "    return norm\n",
    "\n",
    "np.random.seed(0)\n",
    "import h5py\n",
    "with h5py.File(Path(os.environ['INSTANSEG_DATASET_PATH']) / \"monkey_cpg_silver.h5\", \"w\") as f:\n",
    "\n",
    "    f.attrs['class_names'] = str({\"0\": \"lymphocytes\", \"1\": \"monocytes\", \"2\" : \"other\"})  # Convert to string since HDF5 attributes must be simple types\n",
    "    f.attrs['pixel_size'] = destination_pixel_size\n",
    "\n",
    "    for split in ['train', 'val']:\n",
    "        f.create_dataset(f\"{split}/data\", shape=(0, 4, patch_size, patch_size), \n",
    "                        dtype=np.uint8, maxshape=(None, 4, patch_size, patch_size), \n",
    "                        chunks=(1, 4, patch_size, patch_size),\n",
    "                      #  compression = \"lzf\",\n",
    "        )\n",
    "\n",
    "        f.create_dataset(f\"{split}/labels\", shape=(0, 1), dtype=np.uint8, maxshape=(None, 1))\n",
    "\n",
    "\n",
    "    for file in tqdm(files):\n",
    "\n",
    "        split = annotations_dict[file][0][\"split\"]\n",
    "\n",
    "        img_pascpg_path = Path(monkey_dir) / (\"images/pas-cpg/\" + file.split(\".\")[0] + \"_PAS_CPG.tif\")\n",
    "        ihc_path = Path(monkey_dir) / (\"images/ihc/\" + file.split(\".\")[0] + \"_IHC_CPG.tif\")\n",
    "        \n",
    "        slidepascpg = TiffSlide(img_pascpg_path)\n",
    "        slideihc = TiffSlide(ihc_path)\n",
    "\n",
    "        tiles_he,tiles_ihc = get_random_non_empty_tiles(slidepascpg,slideihc, num_images=1000, tile_size=1024) #400\n",
    "\n",
    "\n",
    "        for tile_he,tile_ihc in zip(tiles_he,tiles_ihc):\n",
    "\n",
    "\n",
    "           # show_images(tile_he,tile_ihc,labels)\n",
    "\n",
    "                        \n",
    "            labels , input_tensor = brightfield_nuclei.eval_small_image(tile_he,\n",
    "            pixel_size = 0.2420, rescale_output = False, seed_threshold = 0.05)\n",
    "\n",
    "            ihc_tensor = _rescale_to_pixel_size(_to_tensor_float32(tile_ihc), 0.2420, destination_pixel_size).byte().to(device)\n",
    "\n",
    "            he_tensor = _rescale_to_pixel_size(_to_tensor_float32(tile_he), 0.2420, destination_pixel_size).byte().to(device)\n",
    "\n",
    "            if normalise:\n",
    "                he_tensor = normalise_HE(he_tensor.to(\"cuda\").to(device)),\n",
    "\n",
    "            \n",
    "\n",
    "            if labels.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            assert ihc_tensor.shape[-2:] == he_tensor.shape[-2:]\n",
    "            assert ihc_tensor.shape[-2:] == labels.shape[-2:]\n",
    "\n",
    "            crops,masks = get_masked_patches(labels.to(device),ihc_tensor, patch_size=patch_size)\n",
    "            crops = (crops) / 255\n",
    "            masks = (masks)\n",
    "            x_ihc =(torch.cat((crops,masks),dim= 1))\n",
    "\n",
    "            crops,masks = get_masked_patches(labels.to(device),he_tensor, patch_size=patch_size)\n",
    "            crops = (crops).to(torch.uint8)\n",
    "            masks = (masks).to(torch.uint8)\n",
    "            x =(torch.cat((crops,masks),dim= 1)).cpu().numpy().astype(np.uint8)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_size = 128\n",
    "               # y_hat_he = torch.cat([classifier_he.forward(x[i:i+batch_size].float().to(\"cuda\")) for i in range(0,len(x_ihc),batch_size)],dim = 0)\n",
    "               # y_hat_he = y_hat_he.argmax(dim = 1).cpu()\n",
    "\n",
    "                y_hat= torch.cat([tta_classifier.forward(x_ihc[i:i+batch_size].float().to(\"cuda\")) for i in range(0,len(x_ihc),batch_size)],dim = 0)\n",
    "                y_hat = y_hat.argmax(dim = 1).cpu()\n",
    "\n",
    "          \n",
    "            # show_images(*x_ihc[y_hat == 1][:8,:3],n_cols = 8)\n",
    "            # show_images(*x_ihc[y_hat == 0][:8,:3],n_cols = 8)\n",
    "\n",
    "          #  1/0\n",
    "            \n",
    "            y = y_hat.numpy()[:,None]\n",
    "\n",
    "            unique, counts = np.unique(y, return_counts=True)\n",
    "            min_count = counts.min()\n",
    "            y_subset = np.concatenate([y[y == i][:min_count + 10] for i in range(3)])\n",
    "            x_subset = np.concatenate([x[(y == i).squeeze()][:min_count + 10] for i in range(3)])\n",
    "\n",
    "\n",
    "            if x_subset.ndim == 5:\n",
    "                x_subset = x_subset[0]\n",
    "            x = x_subset\n",
    "            y = y_subset[:,None]\n",
    "\n",
    "            data_ds = f[f\"{split}/data\"]\n",
    "            labels_ds = f[f\"{split}/labels\"]\n",
    "\n",
    "            data_ds.resize((data_ds.shape[0] + x.shape[0],) + x.shape[1:])\n",
    "            data_ds[-x.shape[0]:, ...] = x\n",
    "            labels_ds.resize((labels_ds.shape[0] + y.shape[0],) + y.shape[1:])\n",
    "            labels_ds[-y.shape[0]:, ...] = y.astype(np.uint8)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            # except Exception as e:\n",
    "            #     print(e)\n",
    "            #     continue\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_HE(x):\n",
    "    import torch\n",
    "    import torchstain\n",
    "    normalizer = torchstain.normalizers.MacenkoNormalizer(backend='torch')\n",
    "    normalizer.maxCRef = normalizer.maxCRef.to(\"cuda\")\n",
    "    normalizer.HERef = normalizer.HERef.to(\"cuda\")\n",
    "    norm = normalizer.normalize(I=x, stains=False, Io = 240, beta = 0.01)\n",
    "    norm = torch.clamp(norm[0], 0, 255)\n",
    "    return norm\n",
    "\n",
    "show_images(normalise_HE(he_tensor.to(\"cuda\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import fastremap\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from instanseg.utils.utils import show_images, _move_channel_axis\n",
    "from tiling import get_random_non_empty_tiles\n",
    "from tiffslide import TiffSlide\n",
    "import zarr\n",
    "\n",
    "def normalise_HE(x):\n",
    "    import torch\n",
    "    import torchstain\n",
    "\n",
    "    normalizer = torchstain.normalizers.MacenkoNormalizer(backend='torch')\n",
    "    norm = normalizer.normalize(I=x, stains=False)\n",
    "    norm = torch.clamp(norm[0], 0, 255)\n",
    "\n",
    "    return norm\n",
    "\n",
    "\n",
    "os.environ[\"INSTANSEG_BIOIMAGEIO_PATH\"] = '/home/cdt/Documents/Projects/InstanSeg/instanseg_thibaut/instanseg/bioimageio_models/'\n",
    "os.environ['INSTANSEG_DATASET_PATH'] = \"../datasets/\"\n",
    "\n",
    "from instanseg.instanseg import InstanSeg, _rescale_to_pixel_size, _to_tensor_float32, to_ndim\n",
    "from instanseg.utils.pytorch_utils import get_masked_patches\n",
    "brightfield_nuclei = InstanSeg(\"brightfield_v2\", verbosity=0)\n",
    "\n",
    "os.environ[\"INSTANSEG_OUTPUT_PATH\"] = \"../outputs/\"\n",
    "from utils import get_classifier\n",
    "classifier = get_classifier(\"1922985\").to(\"cuda\").eval()\n",
    "\n",
    "classifier_he = get_classifier(\"test_0\").to(\"cuda\").eval()\n",
    "\n",
    "import ttach as tta\n",
    "transforms = tta.Compose(\n",
    "    [\n",
    "        tta.HorizontalFlip(),\n",
    "        tta.Rotate90(angles=[0, 180]),\n",
    "    ]\n",
    ")\n",
    "tta_classifier = tta.ClassificationTTAWrapper(classifier, transforms, merge_mode='mean').eval()\n",
    "\n",
    "patch_size = 128\n",
    "destination_pixel_size = 0.5\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "monkey_dir = Path(\"../Raw_Datasets/Monkey\")\n",
    "files = os.listdir(os.path.join(monkey_dir, \"annotations\", \"xml\"))\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Create Zarr store\n",
    "dataset_path = Path(os.environ['INSTANSEG_DATASET_PATH']) / \"monkey_cpg_silver_del.zarr\"\n",
    "root = zarr.open(dataset_path, mode=\"w\")\n",
    "\n",
    "# Add metadata\n",
    "root.attrs['class_names'] = {\"0\": \"lymphocytes\", \"1\": \"monocytes\", \"2\": \"other\"}\n",
    "root.attrs['pixel_size'] = destination_pixel_size\n",
    "\n",
    "# Create train/val datasets\n",
    "for split in ['train', 'val']:\n",
    "    root.create_dataset(f\"{split}/data\",\n",
    "                        shape=(0, 4, patch_size, patch_size),\n",
    "                        chunks=(1, 4, patch_size, patch_size),\n",
    "                        dtype=np.uint8,\n",
    "                        compressor=zarr.Blosc(cname='zstd', clevel=5, shuffle=1))  # Compression\n",
    "    root.create_dataset(f\"{split}/labels\",\n",
    "                        shape=(0, 1),\n",
    "                        chunks=(1, 1),\n",
    "                        dtype=np.uint8)\n",
    "\n",
    "# Processing images\n",
    "for file in tqdm(files):\n",
    "    split = annotations_dict[file][0][\"split\"]\n",
    "\n",
    "    img_pascpg_path = Path(monkey_dir) / (\"images/pas-cpg/\" + file.split(\".\")[0] + \"_PAS_CPG.tif\")\n",
    "    ihc_path = Path(monkey_dir) / (\"images/ihc/\" + file.split(\".\")[0] + \"_IHC_CPG.tif\")\n",
    "\n",
    "    slidepascpg = TiffSlide(img_pascpg_path)\n",
    "    slideihc = TiffSlide(ihc_path)\n",
    "\n",
    "    tiles_he, tiles_ihc = get_random_non_empty_tiles(slidepascpg, slideihc, num_images=1, tile_size=1024)\n",
    "\n",
    "    for tile_he, tile_ihc in zip(tiles_he, tiles_ihc):\n",
    "        labels, input_tensor = brightfield_nuclei.eval_small_image(tile_he,\n",
    "                                                                   pixel_size=0.2420,\n",
    "                                                                   rescale_output=False,\n",
    "                                                                   seed_threshold=0.05)\n",
    "\n",
    "        ihc_tensor = _rescale_to_pixel_size(_to_tensor_float32(tile_ihc), 0.2420, destination_pixel_size).byte().to(device)\n",
    "        he_tensor = _rescale_to_pixel_size(_to_tensor_float32(tile_he), 0.2420, destination_pixel_size).byte().to(device)\n",
    "\n",
    "        he_tensor = normalise_HE(he_tensor).byte()\n",
    "\n",
    "      #  show_images(normalise_HE(he_tensor),he_tensor.byte())\n",
    "\n",
    "        if labels.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        assert ihc_tensor.shape[-2:] == he_tensor.shape[-2:]\n",
    "        assert ihc_tensor.shape[-2:] == labels.shape[-2:]\n",
    "\n",
    "        crops, masks = get_masked_patches(labels.to(device), ihc_tensor, patch_size=patch_size)\n",
    "        crops = (crops) / 255\n",
    "        masks = (masks)\n",
    "        x_ihc = (torch.cat((crops, masks), dim=1))\n",
    "\n",
    "        crops, masks = get_masked_patches(labels.to(device), he_tensor, patch_size=patch_size)\n",
    "        crops = (crops).to(torch.uint8)\n",
    "        masks = (masks).to(torch.uint8)\n",
    "        x = (torch.cat((crops, masks), dim=1)).cpu().numpy().astype(np.uint8)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_size = 128\n",
    "            y_hat = torch.cat([tta_classifier.forward(x_ihc[i:i + batch_size].float().to(\"cuda\"))\n",
    "                               for i in range(0, len(x_ihc), batch_size)], dim=0)\n",
    "            y_hat = y_hat.argmax(dim=1).cpu()\n",
    "\n",
    "        y = y_hat.numpy()[:, None]\n",
    "\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        min_count = counts.min()\n",
    "        y_subset = np.concatenate([y[y == i][:min_count + 10] for i in range(3)])\n",
    "        x_subset = np.concatenate([x[(y == i).squeeze()][:min_count + 10] for i in range(3)])\n",
    "\n",
    "        if x_subset.ndim == 5:\n",
    "            x_subset = x_subset[0]\n",
    "        x = x_subset\n",
    "        y = y_subset[:, None]\n",
    "\n",
    "        data_ds = root[f\"{split}/data\"]\n",
    "        labels_ds = root[f\"{split}/labels\"]\n",
    "\n",
    "        # Resize and append to the Zarr dataset\n",
    "        data_ds.append(x)\n",
    "        labels_ds.append(y.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(normalise_HE(he_tensor),he_tensor.byte())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "os.environ[\"INSTANSEG_OUTPUT_PATH\"] = \"/home/cdt/Documents/Projects/InstanSeg/instanseg_classification/instanseg_classification/outputs\"\n",
    "from utils import get_classifier\n",
    "\n",
    "model = \"1937330\"\n",
    "\n",
    "classifier = get_classifier(model).to(\"cpu\").eval()\n",
    "torch.jit.save(torch.jit.script(classifier.path_classifier.eval()), f\"/home/cdt/Documents/Projects/monkey-challenge-instanseg/inference-docker/example_model/{model}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "os.environ[\"INSTANSEG_OUTPUT_PATH\"] = \"/home/cdt/Documents/Projects/InstanSeg/instanseg_classification/instanseg_classification/outputs\"\n",
    "from utils import get_classifier\n",
    "\n",
    "model = \"1937330\"\n",
    "\n",
    "classifier = get_classifier(model).to(\"cpu\").eval()\n",
    "torch.jit.save(torch.jit.trace(classifier.path_classifier.eval(),torch.randn(2,4,128,128).to(\"cpu\")), f\"/home/cdt/Documents/Projects/monkey-challenge-instanseg/inference-docker/example_model/{model}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "os.environ[\"INSTANSEG_OUTPUT_PATH\"] = \"../outputs/\"\n",
    "from utils import get_classifier\n",
    "\n",
    "classifier = get_classifier(\"1923883\").to(\"cpu\").eval()\n",
    "torch.jit.save(torch.jit.script(classifier.path_classifier.eval()), \"/home/cdt/Documents/Projects/monkey-challenge-instanseg/inference-docker/example_model/classifier_large.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightfield_to_fluo(rgb_data):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    from skimage import data\n",
    "    from skimage.color import rgb2hed, hed2rgb\n",
    "\n",
    "    # Separate the stains from the IHC image\n",
    "\n",
    "    rgb_data  = _move_channel_axis(rgb_data, to_back = True)\n",
    "\n",
    "\n",
    "    ihc_hed = rgb2hed(rgb_data)\n",
    "\n",
    "    null = np.zeros_like(ihc_hed[:, :, 0])\n",
    "    ihc_h = hed2rgb(np.stack((ihc_hed[:, :, 0], null, null), axis=-1))\n",
    "    ihc_e = hed2rgb(np.stack((null, ihc_hed[:, :, 1], null), axis=-1))\n",
    "    ihc_d = hed2rgb(np.stack((null, null, ihc_hed[:, :, 2]), axis=-1))\n",
    "\n",
    "    from skimage.exposure import rescale_intensity\n",
    "\n",
    "    # Rescale hematoxylin and DAB channels and give them a fluorescence look\n",
    "    h = rescale_intensity(\n",
    "        ihc_hed[:, :, 0],\n",
    "        out_range=(0, 1),\n",
    "        in_range=(0, np.percentile(ihc_hed[:, :, 0], 99)),\n",
    "    )\n",
    "\n",
    "    e = rescale_intensity(\n",
    "        ihc_hed[:, :, 1],\n",
    "        out_range=(0, 1),\n",
    "        in_range=(0, np.percentile(ihc_hed[:, :, 1], 99)),\n",
    "    )\n",
    "\n",
    "    d = rescale_intensity(\n",
    "        ihc_hed[:, :, 2],\n",
    "        out_range=(0, 1),\n",
    "        in_range=(0, np.percentile(ihc_hed[:, :, 2], 99)),\n",
    "    )\n",
    "\n",
    "    # Cast the two channels into an RGB image, as the blue and green channels\n",
    "    # respectively\n",
    "    zdh = np.stack((h,e,d))\n",
    "\n",
    "    return zdh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instanseg.scripts.train import instanseg_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import fastremap\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from instanseg.utils.utils import show_images, _move_channel_axis\n",
    "from tiling import get_random_non_empty_tiles\n",
    "from tiffslide import TiffSlide\n",
    "\n",
    "os.environ[\"INSTANSEG_BIOIMAGEIO_PATH\"] = '/home/cdt/Documents/Projects/InstanSeg/instanseg_thibaut/instanseg/bioimageio_models/'\n",
    "os.environ['INSTANSEG_DATASET_PATH'] = \"../datasets/\"\n",
    "\n",
    "\n",
    "from instanseg.instanseg import InstanSeg, _rescale_to_pixel_size, _to_tensor_float32, to_ndim\n",
    "from instanseg.utils.pytorch_utils import get_masked_patches\n",
    "brightfield_nuclei = InstanSeg(\"brightfield_nuclei\", verbosity = 0, device = \"cpu\")\n",
    "\n",
    "patch_size = 128\n",
    "destination_pixel_size = 0.5\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "monkey_dir = Path(\"../Raw_Datasets/Monkey\")\n",
    "files = os.listdir(os.path.join(monkey_dir ,\"annotations\",\"xml\"))\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "for file in tqdm(files):\n",
    "\n",
    "    split = annotations_dict[file][0][\"split\"]\n",
    "\n",
    "    img_pascpg_path = Path(monkey_dir) / (\"images/pas-cpg/\" + file.split(\".\")[0] + \"_PAS_CPG.tif\")\n",
    "    ihc_path = Path(monkey_dir) / (\"images/ihc/\" + file.split(\".\")[0] + \"_IHC_CPG.tif\")\n",
    "    \n",
    "    slidepascpg = TiffSlide(img_pascpg_path)\n",
    "    slideihc = TiffSlide(ihc_path)\n",
    "\n",
    "    tiles_he,tiles_ihc = get_random_non_empty_tiles(slidepascpg,slideihc, num_images=1, tile_size=1024) #400\n",
    "\n",
    "\n",
    "    for tile_he,tile_ihc in zip(tiles_he,tiles_ihc):\n",
    "\n",
    "          \n",
    "        labels , input_tensor = brightfield_nuclei.eval_small_image(tile_he,\n",
    "        pixel_size = 0.2420, rescale_output = False, seed_threshold = 0.05)\n",
    "\n",
    "        show_images(tile_he,labels, labels = [1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import PatchDataset\n",
    "\n",
    "train_dataset = PatchDataset(\"../datasets/monkey_cpg_gold.h5\", 'train', batch_size= 128, in_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "def time_loader(loader, N = 10000):\n",
    "    import time\n",
    "    start = time.time()\n",
    "    for i in range(N):\n",
    "        next(iter(loader))\n",
    "    print(f\"{time.time() - start} for {N} trials\")\n",
    "\n",
    "\n",
    "train_dataset = PatchDataset(\"../datasets/monkey_cpg_gold.h5\", 'train', batch_size= 128, in_memory = False)\n",
    "loader = DataLoader(train_dataset, batch_size= 128, num_workers=0, shuffle = True)\n",
    "\n",
    "\n",
    "time_loader(loader, N = 10)\n",
    "\n",
    "time_loader(train_dataset, N = 128 * 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_loader_dataset(dataset, batch_size, N=10000):\n",
    "    import time\n",
    "    start = time.time()\n",
    "    for i in range(N):\n",
    "        # Simulate batching by manually fetching batch_size samples at a time\n",
    "        batch = [dataset[j] for j in range(i * batch_size, (i + 1) * batch_size)]\n",
    "    print(f\"{time.time() - start} for {N} trials of batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "def time_loader(loader, N = 10000):\n",
    "    import time\n",
    "    start = time.time()\n",
    "    for i in range(N):\n",
    "        next(iter(loader))\n",
    "    print(f\"{time.time() - start} for {N} trials\")\n",
    "\n",
    "def time_loader_dataset(dataset, batch_size, N=10000):\n",
    "    import time\n",
    "    start = time.time()\n",
    "    for i in range(N):\n",
    "        # Simulate batching by manually fetching batch_size samples at a time\n",
    "        batch = [dataset[j] for j in range(i * batch_size, (i + 1) * batch_size)]\n",
    "    print(f\"{time.time() - start} for {N} trials of batches\")\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "N_trials = 1000\n",
    "\n",
    "train_dataset = PatchDataset(\"../datasets/monkey_cpg_gold.h5\", 'train', batch_size= 128, in_memory = False)\n",
    "loader = DataLoader(train_dataset, batch_size= batch_size, num_workers=4, persistent_workers = True, shuffle = False)\n",
    "\n",
    "\n",
    "time_loader(loader, N = N_trials)\n",
    "\n",
    "time_loader_dataset(train_dataset, batch_size=batch_size, N=N_trials)\n",
    "\n",
    "\n",
    "\n",
    "train - chunk size (1, 4, 128, 128) num samples 223878\n",
    "(tensor([0, 1, 2]), tensor([ 47651,  22113, 154114]))\n",
    "219.12578701972961 for 1000 trials\n",
    "51.75438141822815 for 1000 trials of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = PatchDataset(\"../datasets/monkey_cpg_gold_gzip.h5\", 'train', batch_size= 128, in_memory = False)\n",
    "loader = DataLoader(train_dataset, batch_size= batch_size, num_workers=4, persistent_workers = True, shuffle = False)\n",
    "\n",
    "\n",
    "time_loader(loader, N = N_trials)\n",
    "\n",
    "time_loader_dataset(train_dataset, batch_size=batch_size, N=N_trials)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset = PatchDataset(\"../datasets/monkey_cpg_gold_lzf.h5\", 'train', batch_size= 128, in_memory = False)\n",
    "loader = DataLoader(train_dataset, batch_size= batch_size, num_workers=0, persistent_workers = True, shuffle = False)\n",
    "\n",
    "\n",
    "time_loader(loader, N = N_trials)\n",
    "\n",
    "time_loader_dataset(train_dataset, batch_size=batch_size, N=N_trials)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset = PatchDataset(\"../datasets/monkey_cpg_gold_lzf.h5\", 'train', batch_size= 128, in_memory = True)\n",
    "loader = DataLoader(train_dataset, batch_size= batch_size, num_workers=0, shuffle = False)\n",
    "\n",
    "\n",
    "time_loader(loader, N = N_trials)\n",
    "\n",
    "time_loader_dataset(train_dataset, batch_size=batch_size, N=N_trials)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "f = h5py.File(\"../datasets/monkey_cpg_gold.h5\",\"r\")\n",
    "\n",
    "d = f[\"train/data\"]\n",
    "d.read_direct(np.s_[0:128])\n",
    "\n",
    "impo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "batch_size = 128\n",
    "\n",
    "def time_loader(loader, N = 10000):\n",
    "    import time\n",
    "    start = time.time()\n",
    "    for i in range(N):\n",
    "        next(iter(loader))\n",
    "    print(f\"{time.time() - start} for {N} trials\")\n",
    "\n",
    "def time_loader_dataset(dataset, batch_size, N=10000):\n",
    "    import time\n",
    "    start = time.time()\n",
    "    for i in range(N):\n",
    "        # Simulate batching by manually fetching batch_size samples at a time\n",
    "        batch = [dataset[j] for j in range(i * batch_size, (i + 1) * batch_size)]\n",
    "    print(f\"{time.time() - start} for {N} trials of batches\")\n",
    "\n",
    "\n",
    "\n",
    "class H5Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.file_path = path\n",
    "        self.dataset = None\n",
    "        with h5py.File(self.file_path, 'r') as file:\n",
    "            self.dataset_len = len(file[\"train/data\"])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.dataset is None:\n",
    "            self.dataset = h5py.File(self.file_path, 'r')[\"train/data\"]\n",
    "        return self.dataset[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_len\n",
    "\n",
    "train_dataset = H5Dataset(\"../datasets/monkey_cpg_gold.h5\")\n",
    "\n",
    "\n",
    "loader = torch.utils.data.DataLoader(train_dataset, batch_size= batch_size, num_workers=0, shuffle = False)\n",
    "\n",
    "time_loader(loader, N = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Print the HDF5 library version\n",
    "print(\"HDF5 library version:\", h5py.version.hdf5_version)\n",
    "\n",
    "# Print the h5py version\n",
    "print(\"h5py version:\", h5py.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Open the HDF5 file and load the dataset\n",
    "file_path = \"../datasets/monkey_cpg_gold_gzip.h5\"\n",
    "with h5py.File(file_path, \"r+\") as f:  # Open in read/write mode to modify\n",
    "    dataset = f[\"train/data\"][:]  # Load the dataset into memory\n",
    "    shuffled_indices = np.random.permutation(len(dataset))  # Shuffle indices\n",
    "    shuffled_data = dataset[shuffled_indices]  # Apply shuffling\n",
    "\n",
    "    # Store the shuffled data back into the file (overwrite or save as a new dataset)\n",
    "    del f[\"train/data\"]  # Delete the old dataset\n",
    "    f.create_dataset(\"train/data\", data=shuffled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
